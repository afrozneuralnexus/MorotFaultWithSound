# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RGPVFLAHUZwX0eRNcDTUeQK_MVz3qReU
"""

import streamlit as st
import tensorflow as tf
import numpy as np
import json
import librosa
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import io
import soundfile as sf

# Page configuration
st.set_page_config(
    page_title="Motor Sound Classifier",
    page_icon="üîä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    .prediction-box {
        padding: 1.5rem;
        border-radius: 10px;
        background-color: #f0f2f6;
        margin: 1rem 0;
    }
    .metric-container {
        text-align: center;
        padding: 1rem;
        background: white;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: bold;
        padding: 0.75rem;
        border-radius: 8px;
    }
    .stButton>button:hover {
        background-color: #1557a0;
        border-color: #1557a0;
    }
    .upload-section {
        border: 2px dashed #1f77b4;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #f8f9fa;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_model_and_metadata():
    """Load the trained model and metadata."""
    model = None

    # Try loading in different formats
    try:
        # Try .keras format first (TensorFlow 2.15+)
        model = tf.keras.models.load_model('motor_sound_classifier.keras')
        st.success("‚úÖ Model loaded successfully (.keras format)")
    except:
        try:
            # Try H5 format
            model = tf.keras.models.load_model('motor_sound_classifier.h5')
            st.success("‚úÖ Model loaded successfully (.h5 format)")
        except:
            try:
                # Try best checkpoint
                model = tf.keras.models.load_model('motor_sound_classifier_best.h5')
                st.success("‚úÖ Model loaded successfully (best checkpoint)")
            except Exception as e:
                st.error(f"‚ùå Error loading model: {e}")
                st.info("Please ensure one of these files exists: motor_sound_classifier.keras, motor_sound_classifier.h5, or motor_sound_classifier_best.h5")
                return None, None

    # Load metadata
    try:
        with open('motor_sound_classifier_metadata.json', 'r') as f:
            metadata = json.load(f)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Could not load metadata file: {e}")
        st.info("Using default metadata values")
        metadata = {
            'class_names': ['engine1_good', 'engine2_broken', 'engine3_heavyload'],
            'sample_rate': 16000,
            'output_sequence_length': 16000,
            'frame_length': 255,
            'frame_step': 128,
            'model_type': 'mel_spectrogram'
        }

    return model, metadata


def get_mel_spectrogram(waveform, metadata):
    """Generate mel spectrogram from waveform."""
    sample_rate = metadata['sample_rate']
    frame_length = metadata['frame_length']
    frame_step = metadata['frame_step']

    # Compute STFT
    spectrogram = tf.signal.stft(
        waveform, frame_length=frame_length, frame_step=frame_step)
    spectrogram = tf.abs(spectrogram)

    # Create mel filterbank
    num_spectrogram_bins = spectrogram.shape[-1]
    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80
    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(
        num_mel_bins, num_spectrogram_bins, sample_rate,
        lower_edge_hertz, upper_edge_hertz)

    mel_spectrograms = tf.tensordot(
        spectrogram, linear_to_mel_weight_matrix, 1)
    mel_spectrograms.set_shape(spectrogram.shape[:-1].concatenate(
        linear_to_mel_weight_matrix.shape[-1:]))

    # Apply log scaling
    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)
    log_mel_spectrograms = log_mel_spectrograms[..., tf.newaxis]

    return log_mel_spectrograms


def preprocess_audio(audio_bytes, metadata):
    """Preprocess audio file for prediction."""
    try:
        # Load audio using soundfile
        audio, sr = sf.read(io.BytesIO(audio_bytes))

        # Convert to mono if stereo
        if len(audio.shape) > 1:
            audio = np.mean(audio, axis=1)

        # Resample if necessary
        if sr != metadata['sample_rate']:
            audio = librosa.resample(audio, orig_sr=sr, target_sr=metadata['sample_rate'])

        # Pad or trim to expected length
        target_length = metadata['output_sequence_length']
        if len(audio) < target_length:
            audio = np.pad(audio, (0, target_length - len(audio)))
        else:
            audio = audio[:target_length]

        # Convert to tensor
        waveform = tf.convert_to_tensor(audio, dtype=tf.float32)

        # Generate spectrogram
        spectrogram = get_mel_spectrogram(waveform, metadata)

        # Add batch dimension
        spectrogram = tf.expand_dims(spectrogram, 0)

        return spectrogram, audio

    except Exception as e:
        st.error(f"Error preprocessing audio: {e}")
        return None, None


def plot_waveform(audio, sr):
    """Plot audio waveform."""
    fig, ax = plt.subplots(figsize=(12, 4))
    time = np.linspace(0, len(audio) / sr, len(audio))
    ax.plot(time, audio, linewidth=0.8, color='#1f77b4', alpha=0.7)
    ax.set_xlabel('Time (s)', fontsize=12)
    ax.set_ylabel('Amplitude', fontsize=12)
    ax.set_title('Audio Waveform', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_xlim([0, len(audio) / sr])
    plt.tight_layout()
    return fig


def plot_spectrogram(spectrogram):
    """Plot mel spectrogram."""
    fig, ax = plt.subplots(figsize=(12, 4))

    # Remove batch and channel dimensions for plotting
    spec_plot = np.squeeze(spectrogram.numpy())

    im = ax.imshow(spec_plot.T, aspect='auto', origin='lower', cmap='viridis')
    ax.set_xlabel('Time Frames', fontsize=12)
    ax.set_ylabel('Mel Frequency Bins', fontsize=12)
    ax.set_title('Mel Spectrogram (Log Scale)', fontsize=14, fontweight='bold')
    cbar = plt.colorbar(im, ax=ax, label='Log Magnitude')
    plt.tight_layout()
    return fig


def plot_predictions(predictions, class_names):
    """Plot prediction probabilities."""
    fig, ax = plt.subplots(figsize=(10, 5))

    probabilities = tf.nn.softmax(predictions[0]).numpy()
    colors = ['#2ecc71' if p == max(probabilities) else '#3498db'
              for p in probabilities]

    # Format class names for better display
    display_names = [name.replace('_', ' ').replace('engine', 'Engine ').title()
                     for name in class_names]

    bars = ax.bar(display_names, probabilities, color=colors, alpha=0.8,
                  edgecolor='black', linewidth=1.5)
    ax.set_ylabel('Probability', fontsize=12, fontweight='bold')
    ax.set_xlabel('Motor State', fontsize=12, fontweight='bold')
    ax.set_title('Prediction Probabilities', fontsize=14, fontweight='bold')
    ax.set_ylim([0, 1])
    ax.grid(axis='y', alpha=0.3, linestyle='--')

    # Add value labels on bars
    for bar, prob in zip(bars, probabilities):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{prob:.2%}',
                ha='center', va='bottom', fontsize=11, fontweight='bold')

    plt.xticks(rotation=15, ha='right')
    plt.tight_layout()
    return fig


def get_motor_status_color(predicted_class):
    """Get color based on motor status."""
    if "good" in predicted_class.lower():
        return "#2ecc71"  # Green
    elif "broken" in predicted_class.lower():
        return "#e74c3c"  # Red
    else:
        return "#f39c12"  # Orange


def display_recommendations(predicted_class, confidence):
    """Display recommendations based on prediction."""
    if "good" in predicted_class.lower():
        st.success("""
        ### ‚úÖ Motor Status: Healthy

        **Analysis**: The motor is operating within normal parameters.

        **Recommendations**:
        - Continue with regular maintenance schedule
        - Monitor periodically for any changes in sound patterns
        - Keep maintenance logs up to date
        - No immediate action required
        """)
    elif "broken" in predicted_class.lower():
        st.error("""
        ### ‚ö†Ô∏è Motor Status: Faulty

        **Analysis**: The motor shows signs of malfunction or damage.

        **Urgent Recommendations**:
        - **Immediate inspection required**
        - Stop operation if safe to do so
        - Check for unusual vibrations, heat, or burning smell
        - Contact maintenance personnel immediately
        - Schedule repair or replacement
        - Document the issue for maintenance records
        """)
    else:
        st.warning("""
        ### ‚ö° Motor Status: Heavy Load

        **Analysis**: The motor is operating under heavy load conditions.

        **Recommendations**:
        - Verify if current load is within motor specifications
        - Monitor temperature and vibration levels closely
        - Check for proper lubrication
        - Consider load balancing or redistribution
        - Evaluate if motor capacity upgrade is needed
        - Ensure adequate cooling and ventilation
        """)


def main():
    # Header
    st.markdown('<h1 class="main-header">üîä Motor Sound Classifier</h1>',
                unsafe_allow_html=True)

    st.markdown("""
    <div class="sub-header">
        <p>AI-Powered Electric Motor Diagnosis System</p>
        <p style="font-size: 0.9rem; color: #999;">
            Upload an audio recording to analyze motor operational state
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Load model
    with st.spinner('üîÑ Loading AI model...'):
        model, metadata = load_model_and_metadata()

    if model is None:
        st.error("‚ö†Ô∏è Failed to load model. Please ensure the model files are in the correct location.")
        st.info("""
        **Required files:**
        - `motor_sound_classifier.keras` or `motor_sound_classifier.h5`
        - `motor_sound_classifier_metadata.json`
        """)
        return

    # Sidebar
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/sound-wave.png", width=80)
        st.header("‚ÑπÔ∏è About This App")
        st.markdown("""
        This application uses deep learning to classify electric motor
        operational states based on audio recordings.

        ### üìä Classification Categories
        """)

        for i, class_name in enumerate(metadata['class_names'], 1):
            display_name = class_name.replace('_', ' ').replace('engine', 'Engine ').title()
            st.markdown(f"**{i}. {display_name}**")

            if "good" in class_name.lower():
                st.markdown("   - ‚úÖ Healthy operation")
            elif "broken" in class_name.lower():
                st.markdown("   - ‚ö†Ô∏è Faulty motor")
            else:
                st.markdown("   - ‚ö° Heavy load condition")

        st.markdown("---")
        st.header("üéµ Supported Formats")
        st.markdown("""
        - WAV (Recommended)
        - MP3
        - OGG
        - FLAC
        - M4A
        """)

        st.markdown("---")
        st.header("üî¨ Model Information")
        st.info(f"""
        **Architecture**: Deep CNN with Mel Spectrograms

        **Classes**: {len(metadata['class_names'])}

        **Sample Rate**: {metadata['sample_rate']} Hz

        **Input Length**: {metadata['output_sequence_length']} samples

        **Type**: {metadata.get('model_type', 'Audio Classification')}
        """)

        st.markdown("---")
        st.header("üìñ How to Use")
        st.markdown("""
        1. Upload motor audio file
        2. Listen to preview
        3. Click 'Analyze Audio'
        4. Review results and recommendations
        """)

    # Main content
    # File uploader
    st.markdown('<div class="upload-section">', unsafe_allow_html=True)
    uploaded_file = st.file_uploader(
        "üìÅ Upload Motor Sound Recording",
        type=['wav', 'mp3', 'ogg', 'flac', 'm4a'],
        help="Select an audio file containing motor sound",
        label_visibility="collapsed"
    )
    st.markdown('</div>', unsafe_allow_html=True)

    if uploaded_file is not None:
        # Display file info
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.success(f"‚úÖ **File**: {uploaded_file.name}")
        with col2:
            st.info(f"üì¶ **Size**: {uploaded_file.size / 1024:.2f} KB")
        with col3:
            st.info(f"üìù **Type**: {uploaded_file.type}")

        # Read audio bytes
        audio_bytes = uploaded_file.read()

        # Audio player
        st.markdown("### üéß Audio Preview")
        st.audio(audio_bytes, format=f'audio/{uploaded_file.name.split(".")[-1]}')

        st.markdown("---")

        # Analyze button
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            analyze_button = st.button("üîç Analyze Audio", type="primary", use_container_width=True)

        if analyze_button:
            with st.spinner('üîÑ Processing audio and generating predictions...'):
                try:
                    # Preprocess audio
                    spectrogram, audio = preprocess_audio(audio_bytes, metadata)

                    if spectrogram is None or audio is None:
                        st.error("Failed to preprocess audio. Please try a different file.")
                        return

                    # Make prediction
                    predictions = model.predict(spectrogram, verbose=0)
                    predicted_class_idx = tf.argmax(predictions[0]).numpy()
                    predicted_class = metadata['class_names'][predicted_class_idx]
                    confidence = tf.nn.softmax(predictions[0])[predicted_class_idx].numpy()

                    # Display results
                    st.markdown("---")
                    st.markdown("## üìä Analysis Results")

                    # Main prediction metrics
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        display_name = predicted_class.replace('_', ' ').replace('engine', 'Engine ').title()
                        st.metric("üéØ Predicted State", display_name)
                        st.markdown('</div>', unsafe_allow_html=True)

                    with col2:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("üìà Confidence", f"{confidence:.1%}")
                        # Add confidence bar
                        st.progress(confidence)
                        st.markdown('</div>', unsafe_allow_html=True)

                    with col3:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        if "good" in predicted_class.lower():
                            status = "‚úÖ Healthy"
                            status_color = "green"
                        elif "broken" in predicted_class.lower():
                            status = "‚ö†Ô∏è Attention Required"
                            status_color = "red"
                        else:
                            status = "‚ö° Monitor Closely"
                            status_color = "orange"
                        st.metric("üîî Status", status)
                        st.markdown('</div>', unsafe_allow_html=True)

                    st.markdown("---")

                    # Prediction probabilities chart
                    st.markdown("### üìä Prediction Probabilities")
                    fig_pred = plot_predictions(predictions, metadata['class_names'])
                    st.pyplot(fig_pred)
                    plt.close()

                    st.markdown("---")

                    # Visualizations
                    st.markdown("### üìà Audio Analysis Visualizations")

                    tab1, tab2 = st.tabs(["üåä Waveform", "üéº Mel Spectrogram"])

                    with tab1:
                        st.markdown("**Time-domain representation of the audio signal**")
                        fig_wave = plot_waveform(audio, metadata['sample_rate'])
                        st.pyplot(fig_wave)
                        plt.close()

                    with tab2:
                        st.markdown("**Frequency-domain representation using mel scale**")
                        fig_spec = plot_spectrogram(spectrogram)
                        st.pyplot(fig_spec)
                        plt.close()

                    st.markdown("---")

                    # Detailed probabilities table
                    st.markdown("### üìã Detailed Classification Probabilities")

                    probs = tf.nn.softmax(predictions[0]).numpy()

                    # Create a nice dataframe
                    prob_data = []
                    for name, prob in zip(metadata['class_names'], probs):
                        display_name = name.replace('_', ' ').replace('engine', 'Engine ').title()
                        prob_data.append({
                            'Motor State': display_name,
                            'Probability': prob,
                            'Percentage': f"{prob:.2%}",
                            'Confidence Bar': '‚ñà' * int(prob * 20)
                        })

                    st.table(prob_data)

                    st.markdown("---")

                    # Recommendations
                    st.markdown("## üí° Recommendations & Next Steps")
                    display_recommendations(predicted_class, confidence)

                    # Additional info
                    if confidence < 0.7:
                        st.warning("""
                        ‚ö†Ô∏è **Note**: The confidence level is below 70%.
                        Consider:
                        - Recording in a quieter environment
                        - Ensuring proper microphone placement
                        - Checking audio quality
                        - Getting a professional inspection
                        """)

                except Exception as e:
                    st.error(f"‚ùå Error during analysis: {e}")
                    st.exception(e)

    else:
        # Instructions when no file is uploaded
        st.markdown("---")
        st.markdown("## üöÄ Getting Started")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            ### üìù Instructions

            1. **Prepare your audio file**
               - Record motor sound in WAV or MP3 format
               - Ensure minimal background noise
               - Recommended: 5-10 seconds of recording

            2. **Upload the file**
               - Click the upload area above
               - Select your audio file

            3. **Analyze**
               - Preview the audio
               - Click 'Analyze Audio' button
               - Review results and recommendations
            """)

        with col2:
            st.markdown("""
            ### üéØ Best Practices

            - **Recording Quality**: Use a quality microphone
            - **Distance**: Place mic 1-2 feet from motor
            - **Environment**: Minimize background noise
            - **Duration**: 5-10 seconds optimal
            - **Format**: WAV files provide best accuracy
            - **Multiple Recordings**: Take several samples
            """)

        st.markdown("---")
        st.info("""
        üí° **Tip**: For best results, record the motor sound in a quiet environment
        with the microphone positioned close to the motor but not touching it.
        """)


if __name__ == "__main__":
    main()