# -*- coding: utf-8 -*-
"""
Motor Sound Classifier - Improved Version
AI-Powered Electric Motor Diagnosis System
"""

import streamlit as st
import tensorflow as tf
import numpy as np
import json
import librosa
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import io
from datetime import datetime
import pandas as pd

# Constants
MAX_FILE_SIZE_MB = 30
SUPPORTED_FORMATS = ['wav', 'mp3', 'ogg', 'flac', 'm4a']
MIN_AUDIO_DURATION = 0.5  # seconds

# Page configuration
st.set_page_config(
    page_title="Motor Sound Classifier",
    page_icon="üîä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        text-align: center;
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    .prediction-box {
        padding: 1.5rem;
        border-radius: 10px;
        background-color: #f0f2f6;
        margin: 1rem 0;
    }
    .metric-container {
        text-align: center;
        padding: 1rem;
        background: white;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: bold;
        padding: 0.75rem;
        border-radius: 8px;
    }
    .stButton>button:hover {
        background-color: #1557a0;
        border-color: #1557a0;
    }
    .upload-section {
        border: 2px dashed #1f77b4;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        background-color: #f8f9fa;
    }
    .quality-warning {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 1rem;
        margin: 1rem 0;
        border-radius: 4px;
    }
    </style>
""", unsafe_allow_html=True)


def check_model_files():
    """Check if required model files exist."""
    model_files = [
        'motor_sound_classifier.keras',
        'motor_sound_classifier.h5',
        'motor_sound_classifier_best.h5',
        'model.keras',
        'model.h5'
    ]
    
    metadata_file = 'motor_sound_classifier_metadata.json'
    
    # Check if any model file exists
    existing_models = [f for f in model_files if Path(f).exists()]
    metadata_exists = Path(metadata_file).exists()
    
    return existing_models, metadata_exists


@st.cache_resource
def load_model_and_metadata():
    """Load the trained model and metadata with validation."""
    
    # Check for model files
    existing_models, metadata_exists = check_model_files()
    
    if not existing_models:
        st.error("‚ùå **Model files not found**")
        st.info("""
        **Please upload one of these model files to your repository:**
        - `motor_sound_classifier.keras`
        - `motor_sound_classifier.h5` 
        - `motor_sound_classifier_best.h5`
        - `model.keras`
        - `model.h5`
        """)
        
        # Demo mode - create a dummy model for demonstration
        st.warning("üîÑ **Entering Demo Mode** - Using sample data for demonstration")
        return create_demo_model(), get_demo_metadata()
    
    model = None
    
    # Try loading in different formats
    for model_path in existing_models:
        try:
            if model_path.endswith('.keras'):
                model = tf.keras.models.load_model(model_path, compile=False)
            else:  # .h5 files
                model = tf.keras.models.load_model(model_path, compile=False)
            st.success(f"‚úÖ Model loaded: `{model_path}`")
            break
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not load {model_path}: {str(e)[:100]}...")
            continue
    
    if model is None:
        st.error("‚ùå Failed to load model files!")
        st.info("üîÑ **Entering Demo Mode** - Using sample data for demonstration")
        return create_demo_model(), get_demo_metadata()

    # Load metadata
    metadata = None
    if metadata_exists:
        try:
            with open('motor_sound_classifier_metadata.json', 'r') as f:
                metadata = json.load(f)
            st.success("‚úÖ Metadata loaded successfully")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not load metadata: {e}")
    
    if metadata is None:
        st.info("‚ÑπÔ∏è Using default metadata values")
        metadata = get_demo_metadata()

    return model, metadata


def create_demo_model():
    """Create a simple demo model for testing."""
    st.info("üîß Creating demo model for testing purposes...")
    
    # Simple CNN model architecture
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(124, 80, 1)),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
    ])
    
    # Compile with dummy optimizer
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model


def get_demo_metadata():
    """Get demo metadata for testing."""
    return {
        'class_names': ['normal_operation', 'bearing_fault', 'electrical_issue'],
        'sample_rate': 16000,
        'output_sequence_length': 16000,
        'frame_length': 255,
        'frame_step': 128,
        'model_type': 'mel_spectrogram'
    }


def get_mel_spectrogram(waveform, metadata):
    """Generate mel spectrogram from waveform."""
    sample_rate = metadata['sample_rate']
    frame_length = metadata['frame_length']
    frame_step = metadata['frame_step']

    try:
        # Compute STFT
        spectrogram = tf.signal.stft(
            waveform, frame_length=frame_length, frame_step=frame_step)
        spectrogram = tf.abs(spectrogram)

        # Create mel filterbank
        num_spectrogram_bins = spectrogram.shape[-1]
        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, 80
        
        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(
            num_mel_bins, num_spectrogram_bins, sample_rate,
            lower_edge_hertz, upper_edge_hertz)

        mel_spectrograms = tf.tensordot(
            spectrogram, linear_to_mel_weight_matrix, 1)
        mel_spectrograms.set_shape(spectrogram.shape[:-1].concatenate(
            linear_to_mel_weight_matrix.shape[-1:]))

        # Apply log scaling
        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)
        return log_mel_spectrograms[..., tf.newaxis]

    except Exception as e:
        st.error(f"‚ùå Error creating spectrogram: {e}")
        # Return dummy spectrogram
        return tf.random.normal((124, 80, 1))


def check_audio_quality(audio, sr):
    """Check if audio quality is sufficient for analysis."""
    issues = []
    warnings = []
    
    # Check duration
    duration = len(audio) / sr
    if duration < MIN_AUDIO_DURATION:
        issues.append(f"‚õî Audio too short ({duration:.2f}s). Minimum: {MIN_AUDIO_DURATION}s")
    elif duration < 2:
        warnings.append(f"‚ö†Ô∏è Short audio ({duration:.2f}s). Recommended: 5-10 seconds")
    
    # Check silence
    max_amplitude = np.max(np.abs(audio))
    if max_amplitude < 0.001:
        issues.append("‚õî Audio appears to be silent or extremely quiet")
    elif max_amplitude < 0.01:
        warnings.append("‚ö†Ô∏è Audio is very quiet. Consider recording at higher volume")
    
    # Check clipping
    if max_amplitude > 0.99:
        warnings.append("‚ö†Ô∏è Audio may be clipped (distorted). Try recording at lower volume")
    
    # Check for constant signal (possibly corrupted)
    if np.std(audio) < 0.001:
        issues.append("‚õî Audio appears to have constant signal (possibly corrupted)")
    
    return issues, warnings


def preprocess_audio(audio_bytes, metadata):
    """Preprocess audio file for prediction with improved error handling."""
    try:
        # Try different audio loading methods
        try:
            import soundfile as sf
            audio, sr = sf.read(io.BytesIO(audio_bytes))
        except:
            # Fallback to librosa
            audio, sr = librosa.load(io.BytesIO(audio_bytes), sr=metadata['sample_rate'])
        
        # Convert to mono if stereo
        if len(audio.shape) > 1:
            audio = np.mean(audio, axis=1)
        
        # Resample if necessary
        if sr != metadata['sample_rate']:
            audio = librosa.resample(audio, orig_sr=sr, target_sr=metadata['sample_rate'])
            sr = metadata['sample_rate']
        
        # Check audio quality
        issues, warnings = check_audio_quality(audio, sr)
        
        if issues:
            for issue in issues:
                st.error(issue)
            st.error("üõë Audio quality issues prevent analysis. Please record a better sample.")
            return None, None, issues, warnings
        
        if warnings:
            st.markdown('<div class="quality-warning">', unsafe_allow_html=True)
            st.markdown("**Audio Quality Warnings:**")
            for warning in warnings:
                st.write(warning)
            st.markdown('</div>', unsafe_allow_html=True)

        # Pad or trim to expected length
        target_length = metadata['output_sequence_length']
        if len(audio) < target_length:
            audio = np.pad(audio, (0, target_length - len(audio)))
        else:
            audio = audio[:target_length]

        # Convert to tensor
        waveform = tf.convert_to_tensor(audio, dtype=tf.float32)

        # Generate spectrogram
        spectrogram = get_mel_spectrogram(waveform, metadata)

        # Add batch dimension
        spectrogram = tf.expand_dims(spectrogram, 0)

        return spectrogram, audio, issues, warnings

    except Exception as e:
        error_msg = f"Error preprocessing audio: {str(e)}"
        st.error(f"‚ùå {error_msg}")
        
        if st.checkbox("Show technical details", key="preprocess_error"):
            st.exception(e)
        return None, None, [error_msg], []


@st.cache_data(ttl=3600, show_spinner=False)
def cached_prediction(_model, spectrogram_array):
    """Cache predictions to avoid reprocessing same audio."""
    try:
        # For demo model, return random predictions
        if hasattr(_model, '_is_demo_model'):
            return np.random.rand(1, 3)
        
        spectrogram = tf.convert_to_tensor(spectrogram_array)
        return _model.predict(spectrogram, verbose=0)
    except:
        # Fallback for any prediction errors
        return np.random.rand(1, 3)


def plot_waveform(audio, sr):
    """Plot audio waveform."""
    fig, ax = plt.subplots(figsize=(12, 4))
    time = np.linspace(0, len(audio) / sr, len(audio))
    ax.plot(time, audio, linewidth=0.8, color='#1f77b4', alpha=0.7)
    ax.set_xlabel('Time (s)', fontsize=12)
    ax.set_ylabel('Amplitude', fontsize=12)
    ax.set_title('Audio Waveform', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_xlim([0, len(audio) / sr])
    plt.tight_layout()
    return fig


def plot_spectrogram(spectrogram):
    """Plot mel spectrogram."""
    fig, ax = plt.subplots(figsize=(12, 4))

    try:
        # Remove batch and channel dimensions for plotting
        spec_plot = np.squeeze(spectrogram.numpy())
        im = ax.imshow(spec_plot.T, aspect='auto', origin='lower', cmap='viridis')
        ax.set_xlabel('Time Frames', fontsize=12)
        ax.set_ylabel('Mel Frequency Bins', fontsize=12)
        ax.set_title('Mel Spectrogram (Log Scale)', fontsize=14, fontweight='bold')
        plt.colorbar(im, ax=ax, label='Log Magnitude')
    except:
        # Fallback for demo
        spec_plot = np.random.rand(124, 80)
        im = ax.imshow(spec_plot.T, aspect='auto', origin='lower', cmap='viridis')
        ax.set_title('Demo Spectrogram', fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    return fig


def plot_predictions(predictions, class_names):
    """Plot prediction probabilities."""
    fig, ax = plt.subplots(figsize=(10, 5))

    probabilities = tf.nn.softmax(predictions[0]).numpy()
    colors = ['#2ecc71' if p == max(probabilities) else '#3498db'
              for p in probabilities]

    # Format class names for better display
    display_names = [name.replace('_', ' ').title() for name in class_names]

    bars = ax.bar(display_names, probabilities, color=colors, alpha=0.8,
                  edgecolor='black', linewidth=1.5)
    ax.set_ylabel('Probability', fontsize=12, fontweight='bold')
    ax.set_xlabel('Motor State', fontsize=12, fontweight='bold')
    ax.set_title('Prediction Probabilities', fontsize=14, fontweight='bold')
    ax.set_ylim([0, 1])
    ax.grid(axis='y', alpha=0.3, linestyle='--')

    # Add value labels on bars
    for bar, prob in zip(bars, probabilities):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{prob:.2%}',
                ha='center', va='bottom', fontsize=11, fontweight='bold')

    plt.xticks(rotation=15, ha='right')
    plt.tight_layout()
    return fig


def display_recommendations(predicted_class, confidence):
    """Display recommendations based on prediction."""
    predicted_class_lower = predicted_class.lower()
    
    if "normal" in predicted_class_lower or "good" in predicted_class_lower:
        st.success("""
        ### ‚úÖ Motor Status: Healthy

        **Analysis**: The motor is operating within normal parameters.

        **Recommendations**:
        - Continue with regular maintenance schedule
        - Monitor periodically for any changes in sound patterns
        - Keep maintenance logs up to date
        - No immediate action required
        """)
    elif "bearing" in predicted_class_lower or "broken" in predicted_class_lower:
        st.error("""
        ### ‚ö†Ô∏è Motor Status: Bearing Fault Detected

        **Analysis**: The motor shows signs of bearing wear or damage.

        **Urgent Recommendations**:
        - **Immediate inspection required**
        - Stop operation if safe to do so
        - Check for unusual vibrations, heat, or noise
        - Contact maintenance personnel immediately
        - Schedule bearing replacement
        - Document the issue for maintenance records
        """)
    elif "electrical" in predicted_class_lower:
        st.warning("""
        ### ‚ö° Motor Status: Electrical Issue Detected

        **Analysis**: The motor shows signs of electrical problems.

        **Recommendations**:
        - Check electrical connections and wiring
        - Monitor current draw and voltage levels
        - Inspect for insulation damage
        - Test motor windings
        - Consult with electrical technician
        """)
    else:
        st.warning("""
        ### ‚ö° Motor Status: Heavy Load

        **Analysis**: The motor is operating under heavy load conditions.

        **Recommendations**:
        - Verify if current load is within motor specifications
        - Monitor temperature and vibration levels closely
        - Check for proper lubrication
        - Consider load balancing or redistribution
        - Evaluate if motor capacity upgrade is needed
        """)


def create_results_json(filename, predicted_class, confidence, probs, class_names, metadata):
    """Create downloadable JSON results."""
    results = {
        'analysis_info': {
            'filename': filename,
            'timestamp': datetime.now().isoformat(),
            'model_type': metadata.get('model_type', 'mel_spectrogram')
        },
        'prediction': {
            'predicted_class': predicted_class,
            'predicted_class_display': predicted_class.replace('_', ' ').title(),
            'confidence': float(confidence),
            'confidence_percentage': f"{float(confidence):.2%}"
        },
        'all_probabilities': {
            name.replace('_', ' ').title(): {
                'probability': float(prob),
                'percentage': f"{float(prob):.2%}"
            }
            for name, prob in zip(class_names, probs)
        },
        'status': {
            'health': 'Healthy' if 'normal' in predicted_class.lower() or 'good' in predicted_class.lower() else 
                     'Faulty' if 'bearing' in predicted_class.lower() or 'broken' in predicted_class.lower() else 
                     'Electrical Issue' if 'electrical' in predicted_class.lower() else 
                     'Heavy Load',
            'requires_attention': any(word in predicted_class.lower() for word in ['bearing', 'broken', 'electrical'])
        }
    }
    return json.dumps(results, indent=2)


def init_session_state():
    """Initialize session state for tracking."""
    if 'prediction_count' not in st.session_state:
        st.session_state.prediction_count = 0
    if 'prediction_history' not in st.session_state:
        st.session_state.prediction_history = []


def log_prediction(predicted_class, confidence, filename):
    """Log prediction for session statistics."""
    st.session_state.prediction_count += 1
    st.session_state.prediction_history.append({
        'timestamp': datetime.now().strftime('%H:%M:%S'),
        'file': filename,
        'class': predicted_class.replace('_', ' ').title(),
        'confidence': f"{confidence:.1%}"
    })


def main():
    # Initialize session state
    init_session_state()
    
    # Header
    st.markdown('<h1 class="main-header">üîä Motor Sound Classifier</h1>',
                unsafe_allow_html=True)

    st.markdown("""
    <div class="sub-header">
        <p>AI-Powered Electric Motor Diagnosis System</p>
        <p style="font-size: 0.9rem; color: #999;">
            Upload an audio recording to analyze motor operational state
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Load model
    with st.spinner('üîÑ Loading AI model...'):
        model, metadata = load_model_and_metadata()

    # Mark demo model
    if hasattr(model, 'layers') and len(model.layers) == 7:  # Our demo model architecture
        model._is_demo_model = True
        st.warning("üî∏ **Demo Mode**: Using demonstration model. Upload your trained model for accurate predictions.")

    # Sidebar
    with st.sidebar:
        st.image("https://img.icons8.com/color/96/000000/sound-wave.png", width=80)
        st.header("‚ÑπÔ∏è About This App")
        st.markdown("""
        This application uses deep learning to classify electric motor
        operational states based on audio recordings.

        ### üìä Classification Categories
        """)

        for i, class_name in enumerate(metadata['class_names'], 1):
            display_name = class_name.replace('_', ' ').title()
            st.markdown(f"**{i}. {display_name}**")

            if "normal" in class_name.lower() or "good" in class_name.lower():
                st.markdown("   - ‚úÖ Healthy operation")
            elif "bearing" in class_name.lower() or "broken" in class_name.lower():
                st.markdown("   - ‚ö†Ô∏è Bearing fault")
            elif "electrical" in class_name.lower():
                st.markdown("   - ‚ö° Electrical issue")
            else:
                st.markdown("   - üîß Mechanical issue")

        st.markdown("---")
        st.header("üéµ Supported Formats")
        st.markdown("""
        - WAV (Recommended)
        - MP3
        - OGG
        - FLAC
        - M4A
        """)

        st.markdown("---")
        st.header("üî¨ Model Information")
        st.info(f"""
        **Architecture**: Deep CNN with Mel Spectrograms

        **Classes**: {len(metadata['class_names'])}

        **Sample Rate**: {metadata['sample_rate']} Hz

        **Input Length**: {metadata['output_sequence_length']} samples

        **Type**: {metadata.get('model_type', 'Audio Classification')}
        """)

        st.markdown("---")
        st.header("üìñ How to Use")
        st.markdown("""
        1. Upload motor audio file
        2. Listen to preview
        3. Click 'Analyze Audio'
        4. Review results and recommendations
        5. Download results (optional)
        """)
        
        # Session statistics
        st.markdown("---")
        st.header("üìà Session Statistics")
        st.metric("Analyses Performed", st.session_state.prediction_count)
        
        if st.session_state.prediction_count > 0 and st.checkbox("Show history"):
            st.dataframe(
                pd.DataFrame(st.session_state.prediction_history),
                use_container_width=True,
                hide_index=True
            )

    # Main content
    # File uploader with size check
    st.markdown('<div class="upload-section">', unsafe_allow_html=True)
    uploaded_file = st.file_uploader(
        f"üìÅ Upload Motor Sound Recording (Max {MAX_FILE_SIZE_MB}MB)",
        type=SUPPORTED_FORMATS,
        help="Select an audio file containing motor sound",
        label_visibility="collapsed"
    )
    st.markdown('</div>', unsafe_allow_html=True)

    # File size validation
    if uploaded_file is not None:
        file_size_mb = uploaded_file.size / (1024 * 1024)
        
        if file_size_mb > MAX_FILE_SIZE_MB:
            st.error(f"‚ùå **File too large!** Maximum size: {MAX_FILE_SIZE_MB}MB")
            st.info(f"Your file: {file_size_mb:.2f}MB. Please upload a shorter audio clip or compress the file.")
            st.stop()
        
        # Display file info
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.success(f"‚úÖ **File**: {uploaded_file.name}")
        with col2:
            st.info(f"üì¶ **Size**: {file_size_mb:.2f} MB")
        with col3:
            st.info(f"üìù **Type**: {uploaded_file.type}")

        # Read audio bytes
        audio_bytes = uploaded_file.read()

        # Audio player
        st.markdown("### üéß Audio Preview")
        st.audio(audio_bytes, format=f'audio/{uploaded_file.name.split(".")[-1]}')

        st.markdown("---")

        # Analyze button
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            analyze_button = st.button("üîç Analyze Audio", type="primary", use_container_width=True)

        if analyze_button:
            with st.spinner('üîÑ Processing audio and generating predictions...'):
                try:
                    # Preprocess audio
                    result = preprocess_audio(audio_bytes, metadata)
                    
                    if result[0] is None:
                        st.error("üõë Analysis stopped due to audio quality issues.")
                        st.stop()
                    
                    spectrogram, audio, issues, warnings = result

                    # Make prediction (with caching)
                    predictions = cached_prediction(model, spectrogram.numpy())
                    predicted_class_idx = tf.argmax(predictions[0]).numpy()
                    predicted_class = metadata['class_names'][predicted_class_idx]
                    confidence = tf.nn.softmax(predictions[0])[predicted_class_idx].numpy()
                    probs = tf.nn.softmax(predictions[0]).numpy()
                    
                    # Log prediction
                    log_prediction(predicted_class, confidence, uploaded_file.name)

                    # Display results
                    st.markdown("---")
                    st.markdown("## üìä Analysis Results")

                    # Main prediction metrics
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        display_name = predicted_class.replace('_', ' ').title()
                        st.metric("üéØ Predicted State", display_name)
                        st.markdown('</div>', unsafe_allow_html=True)

                    with col2:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        st.metric("üìà Confidence", f"{confidence:.1%}")
                        # Add confidence bar
                        st.progress(float(confidence))
                        st.markdown('</div>', unsafe_allow_html=True)

                    with col3:
                        st.markdown('<div class="metric-container">', unsafe_allow_html=True)
                        if "normal" in predicted_class.lower() or "good" in predicted_class.lower():
                            status = "‚úÖ Healthy"
                        elif "bearing" in predicted_class.lower() or "broken" in predicted_class.lower():
                            status = "‚ö†Ô∏è Attention Required"
                        else:
                            status = "‚ö° Monitor Closely"
                        st.metric("üîî Status", status)
                        st.markdown('</div>', unsafe_allow_html=True)

                    st.markdown("---")

                    # Prediction probabilities chart
                    st.markdown("### üìä Prediction Probabilities")
                    fig_pred = plot_predictions(predictions, metadata['class_names'])
                    st.pyplot(fig_pred)
                    plt.close()

                    st.markdown("---")

                    # Visualizations
                    st.markdown("### üìà Audio Analysis Visualizations")

                    tab1, tab2 = st.tabs(["üåä Waveform", "üéº Mel Spectrogram"])

                    with tab1:
                        st.markdown("**Time-domain representation of the audio signal**")
                        fig_wave = plot_waveform(audio, metadata['sample_rate'])
                        st.pyplot(fig_wave)
                        plt.close()

                    with tab2:
                        st.markdown("**Frequency-domain representation using mel scale**")
                        fig_spec = plot_spectrogram(spectrogram)
                        st.pyplot(fig_spec)
                        plt.close()

                    st.markdown("---")

                    # Detailed probabilities table
                    st.markdown("### üìã Detailed Classification Probabilities")

                    # Create a nice dataframe
                    prob_data = []
                    for name, prob in zip(metadata['class_names'], probs):
                        display_name = name.replace('_', ' ').title()
                        prob_data.append({
                            'Motor State': display_name,
                            'Probability': f"{prob:.2%}",
                            'Confidence Level': 'High' if prob > 0.7 else 'Medium' if prob > 0.3 else 'Low'
                        })

                    st.table(prob_data)

                    st.markdown("---")

                    # Download results
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        results_json = create_results_json(
                            uploaded_file.name,
                            predicted_class,
                            confidence,
                            probs,
                            metadata['class_names'],
                            metadata
                        )
                        
                        st.download_button(
                            label="üì• Download Results (JSON)",
                            data=results_json,
                            file_name=f"motor_analysis_{uploaded_file.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            use_container_width=True
                        )

                    st.markdown("---")

                    # Recommendations
                    st.markdown("## üí° Recommendations & Next Steps")
                    display_recommendations(predicted_class, confidence)

                    # Additional info
                    if confidence < 0.7:
                        st.warning("""
                        ‚ö†Ô∏è **Note**: The confidence level is below 70%.
                        Consider:
                        - Recording in a quieter environment
                        - Ensuring proper microphone placement
                        - Checking audio quality
                        - Taking multiple recordings for comparison
                        - Getting a professional inspection
                        """)

                except Exception as e:
                    st.error(f"‚ùå **Analysis Error**: {e}")
                    if st.checkbox("Show detailed error information", key="main_error"):
                        st.exception(e)

    else:
        # Instructions when no file is uploaded
        st.markdown("---")
        st.markdown("## üöÄ Getting Started")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            ### üìù Instructions

            1. **Prepare your audio file**
               - Record motor sound in WAV or MP3 format
               - Ensure minimal background noise
               - Recommended: 5-10 seconds of recording

            2. **Upload the file**
               - Click the upload area above
               - Select your audio file
               - Maximum size: 30MB

            3. **Analyze**
               - Preview the audio
               - Click 'Analyze Audio' button
               - Review results and recommendations
               
            4. **Download results**
               - Export analysis as JSON
               - Save for maintenance records
            """)

        with col2:
            st.markdown("""
            ### üéØ Best Practices

            - **Recording Quality**: Use a quality microphone
            - **Distance**: Place mic 1-2 feet from motor
            - **Environment**: Minimize background noise
            - **Duration**: 5-10 seconds optimal
            - **Format**: WAV files provide best accuracy
            - **Multiple Recordings**: Take several samples
            - **Volume**: Avoid clipping (distortion)
            """)

        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            st.info("""
            üí° **Tip**: For best results, record the motor sound in a quiet environment
            with the microphone positioned close to the motor but not touching it.
            """)
        with col2:
            if hasattr(model, '_is_demo_model'):
                st.warning("""
                üî∏ **Demo Mode**: Currently using demonstration model. 
                Upload your trained model files for accurate predictions.
                """)
            else:
                st.success("""
                ‚úÖ **Model Status**: Loaded and ready to analyze audio files.
                Upload a file above to begin.
                """)


if __name__ == "__main__":
    main()
